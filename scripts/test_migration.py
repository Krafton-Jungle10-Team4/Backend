"""
ì›Œí¬í”Œë¡œìš° ë§ˆì´ê·¸ë ˆì´ì…˜ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸ë¥¼ í…ŒìŠ¤íŠ¸í•˜ê³  ë³€í™˜ ê²°ê³¼ë¥¼ ê²€ì¦í•©ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
    python scripts/test_migration.py
"""

import sys
import os
import json
from typing import Dict, Any

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ PYTHONPATHì— ì¶”ê°€
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from scripts.migrate_workflows_to_v2 import (
    infer_ports_for_node_type,
    infer_port_connections,
    create_variable_mappings,
    convert_legacy_workflow_to_v2,
    WorkflowMigrationError
)


def create_test_legacy_workflow() -> Dict[str, Any]:
    """í…ŒìŠ¤íŠ¸ìš© V1 ì›Œí¬í”Œë¡œìš° ìƒì„±"""
    return {
        "nodes": [
            {
                "id": "start_1",
                "type": "start",
                "position": {"x": 100, "y": 100},
                "data": {}
            },
            {
                "id": "knowledge_1",
                "type": "knowledge",
                "position": {"x": 300, "y": 100},
                "data": {"top_k": 5}
            },
            {
                "id": "llm_1",
                "type": "llm",
                "position": {"x": 500, "y": 100},
                "data": {
                    "model": "gpt-4",
                    "temperature": 0.7,
                    "prompt_template": "{context}\n\nQuestion: {query}\nAnswer:"
                }
            },
            {
                "id": "end_1",
                "type": "end",
                "position": {"x": 700, "y": 100},
                "data": {}
            }
        ],
        "edges": [
            {
                "id": "e1",
                "source": "start_1",
                "target": "knowledge_1"
            },
            {
                "id": "e2",
                "source": "knowledge_1",
                "target": "llm_1"
            },
            {
                "id": "e3",
                "source": "start_1",
                "target": "llm_1"
            },
            {
                "id": "e4",
                "source": "llm_1",
                "target": "end_1"
            }
        ]
    }


def test_infer_ports_for_node_type():
    """í¬íŠ¸ ìŠ¤í‚¤ë§ˆ ì¶”ë¡  í…ŒìŠ¤íŠ¸"""
    print("\n=== í…ŒìŠ¤íŠ¸ 1: í¬íŠ¸ ìŠ¤í‚¤ë§ˆ ì¶”ë¡  ===")

    test_cases = [
        ("start", 0, 2),  # ì…ë ¥ 0ê°œ, ì¶œë ¥ 2ê°œ
        ("knowledge", 1, 3),  # ì…ë ¥ 1ê°œ, ì¶œë ¥ 3ê°œ
        ("llm", 3, 3),  # ì…ë ¥ 3ê°œ, ì¶œë ¥ 3ê°œ
        ("end", 1, 1),  # ì…ë ¥ 1ê°œ, ì¶œë ¥ 1ê°œ
    ]

    for node_type, expected_inputs, expected_outputs in test_cases:
        ports = infer_ports_for_node_type(node_type)
        actual_inputs = len(ports["inputs"])
        actual_outputs = len(ports["outputs"])

        status = "âœ…" if (actual_inputs == expected_inputs and actual_outputs == expected_outputs) else "âŒ"
        print(f"{status} {node_type}: ì…ë ¥ {actual_inputs}/{expected_inputs}, ì¶œë ¥ {actual_outputs}/{expected_outputs}")

    print("í…ŒìŠ¤íŠ¸ 1 ì™„ë£Œ\n")


def test_convert_legacy_workflow():
    """V1 â†’ V2 ë³€í™˜ í…ŒìŠ¤íŠ¸"""
    print("\n=== í…ŒìŠ¤íŠ¸ 2: ì›Œí¬í”Œë¡œìš° ë³€í™˜ ===")

    legacy = create_test_legacy_workflow()
    print(f"ì…ë ¥: ë…¸ë“œ {len(legacy['nodes'])}ê°œ, ì—£ì§€ {len(legacy['edges'])}ê°œ")

    try:
        v2_graph = convert_legacy_workflow_to_v2(legacy)
        print(f"ì¶œë ¥: ë…¸ë“œ {len(v2_graph['nodes'])}ê°œ, ì—£ì§€ {len(v2_graph['edges'])}ê°œ")

        # ê²€ì¦
        errors = []

        # 1. ëª¨ë“  ë…¸ë“œì— í¬íŠ¸ê°€ ìˆëŠ”ì§€ í™•ì¸
        for node in v2_graph["nodes"]:
            if "ports" not in node:
                errors.append(f"ë…¸ë“œ {node['id']}: ports í•„ë“œ ì—†ìŒ")
            else:
                ports = node["ports"]
                if "inputs" not in ports or "outputs" not in ports:
                    errors.append(f"ë…¸ë“œ {node['id']}: ports êµ¬ì¡° ë¶ˆì™„ì „")

        # 2. ëª¨ë“  ì—£ì§€ì— í¬íŠ¸ ì •ë³´ê°€ ìˆëŠ”ì§€ í™•ì¸
        for edge in v2_graph["edges"]:
            if "source_port" not in edge or "target_port" not in edge:
                errors.append(f"ì—£ì§€ {edge['id']}: í¬íŠ¸ ì •ë³´ ì—†ìŒ")

        # 3. ë³€ìˆ˜ ë§¤í•‘ ê²€ì¦
        for node in v2_graph["nodes"]:
            if node["type"] != "start":  # start ë…¸ë“œëŠ” ì…ë ¥ì´ ì—†ìŒ
                if not node.get("variable_mappings"):
                    # ì…ë ¥ì´ ìˆëŠ” ë…¸ë“œëŠ” ë§¤í•‘ì´ ìˆì–´ì•¼ í•¨
                    ports = node.get("ports", {})
                    if ports.get("inputs"):
                        errors.append(f"ë…¸ë“œ {node['id']}: variable_mappings ì—†ìŒ")

        if errors:
            print("âŒ ë³€í™˜ ê²€ì¦ ì‹¤íŒ¨:")
            for error in errors:
                print(f"   - {error}")
        else:
            print("âœ… ë³€í™˜ ê²€ì¦ ì„±ê³µ")

        # ë³€í™˜ ê²°ê³¼ ì¶œë ¥ (ìƒ˜í”Œ)
        print("\në³€í™˜ëœ ë…¸ë“œ ìƒ˜í”Œ (start_1):")
        start_node = next((n for n in v2_graph["nodes"] if n["id"] == "start_1"), None)
        if start_node:
            print(json.dumps(start_node, indent=2, ensure_ascii=False))

        print("\në³€í™˜ëœ ì—£ì§€ ìƒ˜í”Œ (e1):")
        edge = next((e for e in v2_graph["edges"] if e["id"] == "e1"), None)
        if edge:
            print(json.dumps(edge, indent=2, ensure_ascii=False))

        print("\nknowledge_1 ë…¸ë“œì˜ variable_mappings:")
        knowledge_node = next((n for n in v2_graph["nodes"] if n["id"] == "knowledge_1"), None)
        if knowledge_node:
            print(json.dumps(knowledge_node["variable_mappings"], indent=2, ensure_ascii=False))

        return len(errors) == 0

    except WorkflowMigrationError as e:
        print(f"âŒ ë³€í™˜ ì‹¤íŒ¨: {e}")
        return False

    finally:
        print("\ní…ŒìŠ¤íŠ¸ 2 ì™„ë£Œ\n")


def test_error_handling():
    """ì—ëŸ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
    print("\n=== í…ŒìŠ¤íŠ¸ 3: ì—ëŸ¬ ì²˜ë¦¬ ===")

    test_cases = [
        ("ë¹ˆ ì›Œí¬í”Œë¡œìš°", {}),
        ("ë…¸ë“œ ì—†ìŒ", {"nodes": [], "edges": []}),
        ("íƒ€ì… ì—†ëŠ” ë…¸ë“œ", {
            "nodes": [{"id": "node1", "position": {"x": 0, "y": 0}}],
            "edges": []
        }),
        ("None ì…ë ¥", None)
    ]

    for name, workflow in test_cases:
        try:
            convert_legacy_workflow_to_v2(workflow)
            print(f"âŒ {name}: ì˜ˆì™¸ê°€ ë°œìƒí•´ì•¼ í•¨")
        except WorkflowMigrationError as e:
            print(f"âœ… {name}: ì˜ˆìƒëœ ì˜ˆì™¸ ë°œìƒ ({str(e)[:50]}...)")
        except Exception as e:
            print(f"âš ï¸  {name}: ì˜ˆìƒì¹˜ ëª»í•œ ì˜ˆì™¸ ({type(e).__name__})")

    print("\ní…ŒìŠ¤íŠ¸ 3 ì™„ë£Œ\n")


def test_complex_workflow():
    """ë³µì¡í•œ ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸"""
    print("\n=== í…ŒìŠ¤íŠ¸ 4: ë³µì¡í•œ ì›Œí¬í”Œë¡œìš° ===")

    # ì—¬ëŸ¬ knowledge ë…¸ë“œê°€ ìˆëŠ” ê²½ìš°
    complex_workflow = {
        "nodes": [
            {"id": "start_1", "type": "start", "position": {"x": 0, "y": 0}, "data": {}},
            {"id": "knowledge_1", "type": "knowledge", "position": {"x": 200, "y": 0}, "data": {"top_k": 3}},
            {"id": "knowledge_2", "type": "knowledge", "position": {"x": 200, "y": 200}, "data": {"top_k": 5}},
            {"id": "llm_1", "type": "llm", "position": {"x": 400, "y": 100}, "data": {"model": "gpt-4"}},
            {"id": "end_1", "type": "end", "position": {"x": 600, "y": 100}, "data": {}}
        ],
        "edges": [
            {"id": "e1", "source": "start_1", "target": "knowledge_1"},
            {"id": "e2", "source": "start_1", "target": "knowledge_2"},
            {"id": "e3", "source": "knowledge_1", "target": "llm_1"},
            {"id": "e4", "source": "start_1", "target": "llm_1"},
            {"id": "e5", "source": "llm_1", "target": "end_1"}
        ]
    }

    try:
        v2_graph = convert_legacy_workflow_to_v2(complex_workflow)
        print(f"âœ… ë³µì¡í•œ ì›Œí¬í”Œë¡œìš° ë³€í™˜ ì„±ê³µ")
        print(f"   ë…¸ë“œ: {len(v2_graph['nodes'])}ê°œ, ì—£ì§€: {len(v2_graph['edges'])}ê°œ")

        # LLM ë…¸ë“œ ë³€ìˆ˜ ë§¤í•‘ í™•ì¸ (2ê°œì˜ ì…ë ¥ì´ ìˆì–´ì•¼ í•¨)
        llm_node = next((n for n in v2_graph["nodes"] if n["id"] == "llm_1"), None)
        if llm_node:
            mappings = llm_node.get("variable_mappings", {})
            print(f"   LLM ë…¸ë“œ ë§¤í•‘: {len(mappings)}ê°œ ì…ë ¥")
            if "query" in mappings and "context" in mappings:
                print("   âœ… queryì™€ context ë§¤í•‘ ì¡´ì¬")
            else:
                print(f"   âš ï¸  ì˜ˆìƒ ë§¤í•‘: query, context")
                print(f"   ì‹¤ì œ ë§¤í•‘: {list(mappings.keys())}")

        return True

    except Exception as e:
        print(f"âŒ ë³µì¡í•œ ì›Œí¬í”Œë¡œìš° ë³€í™˜ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False

    finally:
        print("\ní…ŒìŠ¤íŠ¸ 4 ì™„ë£Œ\n")


def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    print("=" * 60)
    print("ì›Œí¬í”Œë¡œìš° ë§ˆì´ê·¸ë ˆì´ì…˜ í…ŒìŠ¤íŠ¸")
    print("=" * 60)

    results = []

    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    test_infer_ports_for_node_type()
    results.append(("í¬íŠ¸ ìŠ¤í‚¤ë§ˆ ì¶”ë¡ ", True))  # í•­ìƒ í†µê³¼ë¡œ ê°„ì£¼

    result2 = test_convert_legacy_workflow()
    results.append(("ì›Œí¬í”Œë¡œìš° ë³€í™˜", result2))

    test_error_handling()
    results.append(("ì—ëŸ¬ ì²˜ë¦¬", True))  # í•­ìƒ í†µê³¼ë¡œ ê°„ì£¼

    result4 = test_complex_workflow()
    results.append(("ë³µì¡í•œ ì›Œí¬í”Œë¡œìš°", result4))

    # ê²°ê³¼ ìš”ì•½
    print("=" * 60)
    print("í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print("=" * 60)

    passed = sum(1 for _, result in results if result)
    total = len(results)

    for name, result in results:
        status = "âœ…" if result else "âŒ"
        print(f"{status} {name}")

    print(f"\nì´ {passed}/{total} í…ŒìŠ¤íŠ¸ í†µê³¼")

    if passed == total:
        print("\nğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼!")
        return 0
    else:
        print(f"\nâš ï¸  {total - passed}ê°œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
        return 1


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
