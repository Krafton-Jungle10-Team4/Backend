"""
ì›Œí¬í”Œë¡œìš° V1 â†’ V2 ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸

ê¸°ì¡´ ì›Œí¬í”Œë¡œìš°ë¥¼ V2 í¬íŠ¸ ê¸°ë°˜ ì‹œìŠ¤í…œìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
    # Dry run (ì‹œë®¬ë ˆì´ì…˜)
    python scripts/migrate_workflows_to_v2.py --dry-run

    # ì‹¤ì œ ë§ˆì´ê·¸ë ˆì´ì…˜
    python scripts/migrate_workflows_to_v2.py

    # íŠ¹ì • ë´‡ë§Œ ë§ˆì´ê·¸ë ˆì´ì…˜
    python scripts/migrate_workflows_to_v2.py --bot-id abc-123

    # Verbose ëª¨ë“œ
    python scripts/migrate_workflows_to_v2.py --verbose
"""

import sys
import os
import asyncio
import argparse
from datetime import datetime
from typing import Dict, Any, List, Optional, Tuple

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ PYTHONPATHì— ì¶”ê°€
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from sqlalchemy.orm import Session
from sqlalchemy import func
from app.core.database import SessionLocal
from app.models.bot import Bot
from app.models.workflow_version import BotWorkflowVersion
from app.schemas.workflow import WorkflowVersionStatus


class WorkflowMigrationError(Exception):
    """ë§ˆì´ê·¸ë ˆì´ì…˜ ì˜¤ë¥˜"""
    pass


def infer_ports_for_node_type(node_type: str) -> Dict[str, Any]:
    """
    ë…¸ë“œ íƒ€ì…ë³„ í¬íŠ¸ ìŠ¤í‚¤ë§ˆ ì¶”ë¡ 

    Args:
        node_type: ë…¸ë“œ íƒ€ì… (start, knowledge, llm, end)

    Returns:
        Dict: í¬íŠ¸ ìŠ¤í‚¤ë§ˆ ì •ì˜
    """
    port_schemas = {
        "start": {
            "inputs": [],
            "outputs": [
                {
                    "name": "query",
                    "type": "string",
                    "required": True,
                    "description": "ì‚¬ìš©ì ì§ˆë¬¸ ë˜ëŠ” ë©”ì‹œì§€",
                    "display_name": "ì‚¬ìš©ì ì§ˆë¬¸"
                },
                {
                    "name": "session_id",
                    "type": "string",
                    "required": False,
                    "description": "ì„¸ì…˜ ì‹ë³„ì",
                    "display_name": "ì„¸ì…˜ ID"
                }
            ]
        },
        "knowledge": {
            "inputs": [
                {
                    "name": "query",
                    "type": "string",
                    "required": True,
                    "description": "ê²€ìƒ‰í•  ì¿¼ë¦¬ í…ìŠ¤íŠ¸",
                    "display_name": "ê²€ìƒ‰ ì¿¼ë¦¬"
                }
            ],
            "outputs": [
                {
                    "name": "context",
                    "type": "string",
                    "required": True,
                    "description": "ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì„ ë³‘í•©í•œ ì»¨í…ìŠ¤íŠ¸ í…ìŠ¤íŠ¸",
                    "display_name": "ì»¨í…ìŠ¤íŠ¸"
                },
                {
                    "name": "documents",
                    "type": "array",
                    "required": False,
                    "description": "ê²€ìƒ‰ëœ ë¬¸ì„œ ëª©ë¡ (ë©”íƒ€ë°ì´í„° í¬í•¨)",
                    "display_name": "ë¬¸ì„œ ëª©ë¡"
                },
                {
                    "name": "doc_count",
                    "type": "number",
                    "required": False,
                    "description": "ê²€ìƒ‰ëœ ë¬¸ì„œ ê°œìˆ˜",
                    "display_name": "ë¬¸ì„œ ê°œìˆ˜"
                }
            ]
        },
        "llm": {
            "inputs": [
                {
                    "name": "query",
                    "type": "string",
                    "required": True,
                    "description": "ì‚¬ìš©ì ì§ˆë¬¸",
                    "display_name": "ì§ˆë¬¸"
                },
                {
                    "name": "context",
                    "type": "string",
                    "required": False,
                    "description": "ì»¨í…ìŠ¤íŠ¸ ì •ë³´ (ê²€ìƒ‰ ê²°ê³¼ ë“±)",
                    "display_name": "ì»¨í…ìŠ¤íŠ¸"
                },
                {
                    "name": "system_prompt",
                    "type": "string",
                    "required": False,
                    "description": "ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸",
                    "display_name": "ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸"
                }
            ],
            "outputs": [
                {
                    "name": "response",
                    "type": "string",
                    "required": True,
                    "description": "LLM ìƒì„± ì‘ë‹µ",
                    "display_name": "ì‘ë‹µ"
                },
                {
                    "name": "tokens",
                    "type": "number",
                    "required": False,
                    "description": "ì‚¬ìš©ëœ í† í° ìˆ˜",
                    "display_name": "í† í° ìˆ˜"
                },
                {
                    "name": "model",
                    "type": "string",
                    "required": False,
                    "description": "ì‚¬ìš©ëœ ëª¨ë¸ëª…",
                    "display_name": "ëª¨ë¸"
                }
            ]
        },
        "end": {
            "inputs": [
                {
                    "name": "response",
                    "type": "string",
                    "required": True,
                    "description": "ìµœì¢… ì‘ë‹µ í…ìŠ¤íŠ¸",
                    "display_name": "ì‘ë‹µ"
                }
            ],
            "outputs": [
                {
                    "name": "final_output",
                    "type": "object",
                    "required": True,
                    "description": "ìµœì¢… ê²°ê³¼ ê°ì²´",
                    "display_name": "ìµœì¢… ê²°ê³¼"
                }
            ]
        }
    }

    return port_schemas.get(node_type, {"inputs": [], "outputs": []})


def infer_port_connections(edges: List[Dict], nodes: List[Dict]) -> List[Dict]:
    """
    ì—£ì§€ì—ì„œ í¬íŠ¸ ì—°ê²° ì •ë³´ ì¶”ë¡ 

    Args:
        edges: ê¸°ì¡´ ì—£ì§€ ëª©ë¡
        nodes: ë…¸ë“œ ëª©ë¡ (í¬íŠ¸ ì •ë³´ í¬í•¨)

    Returns:
        List[Dict]: í¬íŠ¸ ì •ë³´ê°€ ì¶”ê°€ëœ ì—£ì§€ ëª©ë¡
    """
    # ë…¸ë“œ íƒ€ì… ë§µ ìƒì„±
    node_type_map = {node["id"]: node["type"] for node in nodes}

    v2_edges = []
    for edge in edges:
        source_node_type = node_type_map.get(edge["source"])
        target_node_type = node_type_map.get(edge["target"])

        if not source_node_type or not target_node_type:
            continue

        # í¬íŠ¸ ì´ë¦„ ì¶”ë¡ 
        source_port, target_port = infer_port_names(
            source_node_type,
            target_node_type
        )

        v2_edge = {
            "id": edge["id"],
            "source": edge["source"],
            "target": edge["target"],
            "source_port": source_port,
            "target_port": target_port,
            "data_type": "string"  # ê¸°ë³¸ê°’
        }

        v2_edges.append(v2_edge)

    return v2_edges


def infer_port_names(source_type: str, target_type: str) -> Tuple[str, str]:
    """
    ë…¸ë“œ íƒ€ì… ìŒì—ì„œ í¬íŠ¸ ì´ë¦„ ì¶”ë¡ 

    Args:
        source_type: ì†ŒìŠ¤ ë…¸ë“œ íƒ€ì…
        target_type: íƒ€ê²Ÿ ë…¸ë“œ íƒ€ì…

    Returns:
        Tuple[str, str]: (source_port, target_port)
    """
    # ì¼ë°˜ì ì¸ ì—°ê²° íŒ¨í„´
    port_mappings = {
        ("start", "knowledge"): ("query", "query"),
        ("start", "llm"): ("query", "query"),
        ("knowledge", "llm"): ("context", "context"),
        ("llm", "end"): ("response", "response"),
    }

    return port_mappings.get((source_type, target_type), ("output", "input"))


def create_variable_mappings(edges: List[Dict], node_id: str) -> Dict[str, Any]:
    """
    íŠ¹ì • ë…¸ë“œì˜ ì…ë ¥ í¬íŠ¸ì— ëŒ€í•œ ë³€ìˆ˜ ë§¤í•‘ ìƒì„±

    Args:
        edges: V2 ì—£ì§€ ëª©ë¡
        node_id: ë…¸ë“œ ID

    Returns:
        Dict: ë³€ìˆ˜ ë§¤í•‘ {port_name: {variable: "source_node.source_port"}}
    """
    mappings = {}

    for edge in edges:
        if edge["target"] == node_id and edge.get("target_port"):
            mappings[edge["target_port"]] = {
                "variable": f"{edge['source']}.{edge['source_port']}",
                "value_type": edge.get("data_type", "string")
            }

    return mappings


def convert_legacy_workflow_to_v2(legacy_workflow: Dict[str, Any]) -> Dict[str, Any]:
    """
    ê¸°ì¡´ ì›Œí¬í”Œë¡œìš°ë¥¼ V2 ê·¸ë˜í”„ë¡œ ë³€í™˜

    Args:
        legacy_workflow: ê¸°ì¡´ ì›Œí¬í”Œë¡œìš° JSON

    Returns:
        Dict: V2 ê·¸ë˜í”„

    Raises:
        WorkflowMigrationError: ë³€í™˜ ì‹¤íŒ¨ ì‹œ
    """
    if not legacy_workflow or not isinstance(legacy_workflow, dict):
        raise WorkflowMigrationError("Invalid legacy workflow format")

    nodes = legacy_workflow.get("nodes", [])
    edges = legacy_workflow.get("edges", [])

    if not nodes:
        raise WorkflowMigrationError("No nodes found in workflow")

    # Step 1: ë…¸ë“œì— í¬íŠ¸ ì •ë³´ ì¶”ê°€
    v2_nodes = []
    for node in nodes:
        node_type = node.get("type")
        if not node_type:
            raise WorkflowMigrationError(f"Node {node.get('id')} has no type")

        # í¬íŠ¸ ìŠ¤í‚¤ë§ˆ ì¶”ê°€
        ports = infer_ports_for_node_type(node_type)

        v2_node = {
            "id": node["id"],
            "type": node["type"],
            "position": node.get("position", {"x": 0, "y": 0}),
            "data": node.get("data", {}),
            "ports": ports,
            "variable_mappings": {}  # ë‚˜ì¤‘ì— ì±„ì›Œì§
        }

        v2_nodes.append(v2_node)

    # Step 2: ì—£ì§€ì— í¬íŠ¸ ì •ë³´ ì¶”ê°€
    v2_edges = infer_port_connections(edges, v2_nodes)

    # Step 3: ê° ë…¸ë“œì˜ ë³€ìˆ˜ ë§¤í•‘ ìƒì„±
    for node in v2_nodes:
        node["variable_mappings"] = create_variable_mappings(v2_edges, node["id"])

    return {
        "nodes": v2_nodes,
        "edges": v2_edges
    }


async def migrate_bot_to_v2(
    db: Session,
    bot: Bot,
    dry_run: bool = False,
    verbose: bool = False
) -> Tuple[bool, Optional[str]]:
    """
    ê°œë³„ ë´‡ì„ V2ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜

    Args:
        db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
        bot: ë´‡ ê°ì²´
        dry_run: Trueë©´ ì‹¤ì œ ë³€ê²½í•˜ì§€ ì•ŠìŒ
        verbose: ìƒì„¸ ë¡œê·¸ ì¶œë ¥

    Returns:
        Tuple[bool, Optional[str]]: (ì„±ê³µ ì—¬ë¶€, ì˜¤ë¥˜ ë©”ì‹œì§€)
    """
    bot_id = str(bot.bot_id)

    # ì›Œí¬í”Œë¡œìš°ê°€ ì—†ìœ¼ë©´ ìŠ¤í‚µ
    if not bot.workflow:
        if verbose:
            print(f"  â­ï¸  ë´‡ {bot_id}: ì›Œí¬í”Œë¡œìš° ì—†ìŒ, ìŠ¤í‚µ")
        return True, None

    # ì´ë¯¸ V2ë¥¼ ì‚¬ìš© ì¤‘ì´ë©´ ìŠ¤í‚µ
    if bot.use_workflow_v2:
        if verbose:
            print(f"  â­ï¸  ë´‡ {bot_id}: ì´ë¯¸ V2 ì‚¬ìš© ì¤‘, ìŠ¤í‚µ")
        return True, None

    try:
        # V2 ê·¸ë˜í”„ë¡œ ë³€í™˜
        v2_graph = convert_legacy_workflow_to_v2(bot.workflow)

        if dry_run:
            if verbose:
                print(f"  âœ… ë´‡ {bot_id}: ë³€í™˜ ì„±ê³µ (dry run)")
                print(f"     ë…¸ë“œ ìˆ˜: {len(v2_graph['nodes'])}, ì—£ì§€ ìˆ˜: {len(v2_graph['edges'])}")
            return True, None

        # ê¸°ì¡´ draftê°€ ìˆëŠ”ì§€ í™•ì¸
        existing_draft = db.query(BotWorkflowVersion).filter(
            BotWorkflowVersion.bot_id == bot.bot_id,
            BotWorkflowVersion.status == WorkflowVersionStatus.DRAFT
        ).first()

        if existing_draft:
            # ê¸°ì¡´ draft ì—…ë°ì´íŠ¸
            existing_draft.graph = v2_graph
            existing_draft.updated_at = datetime.now()
            if verbose:
                print(f"  ğŸ”„ ë´‡ {bot_id}: ê¸°ì¡´ draft ì—…ë°ì´íŠ¸")
        else:
            # ìƒˆ draft ìƒì„±
            draft = BotWorkflowVersion(
                bot_id=bot.bot_id,
                version="draft",
                status=WorkflowVersionStatus.DRAFT,
                graph=v2_graph,
                environment_variables={},
                created_by=bot.user_id if hasattr(bot, 'user_id') else None
            )
            db.add(draft)
            if verbose:
                print(f"  â• ë´‡ {bot_id}: ìƒˆ draft ìƒì„±")

        # ê¸°ì¡´ ì›Œí¬í”Œë¡œìš° ë°±ì—…
        if not bot.legacy_workflow:
            bot.legacy_workflow = bot.workflow
            if verbose:
                print(f"  ğŸ’¾ ë´‡ {bot_id}: ê¸°ì¡´ ì›Œí¬í”Œë¡œìš° ë°±ì—… ì™„ë£Œ")

        # use_workflow_v2ëŠ” ìˆ˜ë™ í™œì„±í™”ë¥¼ ìœ„í•´ False ìœ ì§€

        db.commit()

        print(f"  âœ… ë´‡ {bot_id}: ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ")
        return True, None

    except Exception as e:
        error_msg = str(e)
        print(f"  âŒ ë´‡ {bot_id}: ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨ - {error_msg}")
        db.rollback()
        return False, error_msg


async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description="ì›Œí¬í”Œë¡œìš° V1 â†’ V2 ë§ˆì´ê·¸ë ˆì´ì…˜",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=__doc__
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="ì‹¤ì œ ë³€ê²½ ì—†ì´ ì‹œë®¬ë ˆì´ì…˜ë§Œ ìˆ˜í–‰"
    )
    parser.add_argument(
        "--bot-id",
        help="íŠ¹ì • ë´‡ë§Œ ë§ˆì´ê·¸ë ˆì´ì…˜ (ë´‡ ID ì§€ì •)"
    )
    parser.add_argument(
        "--verbose", "-v",
        action="store_true",
        help="ìƒì„¸í•œ ë¡œê·¸ ì¶œë ¥"
    )
    parser.add_argument(
        "--limit",
        type=int,
        help="ë§ˆì´ê·¸ë ˆì´ì…˜í•  ìµœëŒ€ ë´‡ ìˆ˜ ì œí•œ"
    )

    args = parser.parse_args()

    # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
    db = SessionLocal()

    try:
        print("=" * 60)
        print("ì›Œí¬í”Œë¡œìš° V1 â†’ V2 ë§ˆì´ê·¸ë ˆì´ì…˜")
        print("=" * 60)

        if args.dry_run:
            print("âš ï¸  DRY RUN ëª¨ë“œ: ì‹¤ì œ ë³€ê²½ ì—†ì´ ì‹œë®¬ë ˆì´ì…˜ë§Œ ìˆ˜í–‰í•©ë‹ˆë‹¤\n")

        # ë§ˆì´ê·¸ë ˆì´ì…˜ ëŒ€ìƒ ë´‡ ì¡°íšŒ
        query = db.query(Bot).filter(Bot.workflow.isnot(None))

        if args.bot_id:
            query = query.filter(Bot.bot_id == args.bot_id)

        if args.limit:
            query = query.limit(args.limit)

        bots = query.all()

        if not bots:
            print("âš ï¸  ë§ˆì´ê·¸ë ˆì´ì…˜í•  ë´‡ì´ ì—†ìŠµë‹ˆë‹¤.")
            return

        total_count = len(bots)
        print(f"ğŸ“‹ ì´ {total_count}ê°œ ë´‡ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘...\n")

        # ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰
        success_count = 0
        failed_count = 0
        skipped_count = 0

        for i, bot in enumerate(bots, 1):
            print(f"[{i}/{total_count}] ë´‡ ì²˜ë¦¬ ì¤‘...")

            success, error = await migrate_bot_to_v2(
                db=db,
                bot=bot,
                dry_run=args.dry_run,
                verbose=args.verbose
            )

            if success:
                if error is None:
                    success_count += 1
                else:
                    skipped_count += 1
            else:
                failed_count += 1

            print()

        # ê²°ê³¼ ìš”ì•½
        print("=" * 60)
        print("ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ")
        print("=" * 60)
        print(f"âœ… ì„±ê³µ: {success_count}ê°œ")
        print(f"â­ï¸  ìŠ¤í‚µ: {skipped_count}ê°œ")
        print(f"âŒ ì‹¤íŒ¨: {failed_count}ê°œ")
        print(f"ğŸ“Š ì´ê³„: {total_count}ê°œ")

        if args.dry_run:
            print("\nâš ï¸  DRY RUN ëª¨ë“œì˜€ìœ¼ë¯€ë¡œ ì‹¤ì œ ë³€ê²½ì€ ì—†ìŠµë‹ˆë‹¤.")
            print("   ì‹¤ì œ ë§ˆì´ê·¸ë ˆì´ì…˜ì„ ìˆ˜í–‰í•˜ë ¤ë©´ --dry-run ì˜µì…˜ ì—†ì´ ì‹¤í–‰í•˜ì„¸ìš”.")
        else:
            print("\nâœ… ë§ˆì´ê·¸ë ˆì´ì…˜ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            print("   ê° ë´‡ì˜ draft ë²„ì „ì„ ê²€í† í•œ í›„ ë°œí–‰(publish)í•˜ì„¸ìš”.")
            print("   ë°œí–‰ í›„ ë´‡ì˜ use_workflow_v2 í”Œë˜ê·¸ê°€ ìë™ìœ¼ë¡œ í™œì„±í™”ë©ë‹ˆë‹¤.")

    except Exception as e:
        print(f"\nâŒ ì¹˜ëª…ì  ì˜¤ë¥˜: {str(e)}")
        import traceback
        traceback.print_exc()
        return 1

    finally:
        db.close()

    return 0 if failed_count == 0 else 1


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
